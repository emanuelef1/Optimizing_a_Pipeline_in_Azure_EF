# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
In this project we want to compare HyperDrive and AutoML. The goal is to use HyperDrive to find the best hypeparameter for our trainig model and then compare it with AutoML and the model found by AutoML. 

The project is based on the UCI bank marketing data dataset and the goal is to predict whether a user will subscribe a term deposit.

The dataset is composed by 21 columns split into bank data client:

1 - age (numeric)
2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')
3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)
4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')
5 - default: has credit in default? (categorical: 'no','yes','unknown')
6 - housing: has housing loan? (categorical: 'no','yes','unknown')
7 - loan: has personal loan? (categorical: 'no','yes','unknown')

and other attributes:
8 - contact: contact communication type (categorical: 'cellular','telephone')
9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')
10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')
11 - durationand other attributes

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
The best model was the **VotingEnsemble** found by AutoML with an accuracy of **0.91557**.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

As mentioned we have two approach: hyperparameter tuning and AutoML.

## Hyperparameter tuning
In this part of the architecture we want to optimize our model using HyperDrive. HyperDrive is a tool in Azure ML that helps in tuning hyperparameters.
The algorithm in the train.py is sklearn _LogisticRegression_ and the hyperparameters to optimize are C and max-iter of _LogisticRegression_

The architecture is composed by a train script and a notebook.
In the _train.py_ script the CSV file data is loaded into a Azure tabular Dataset from a URL, then data is cleaned and split into train and test sets.


In the notebook a HyperDriveConfig is created passing a parameter sampler, a early termination policy and an estimator. 
In the configuration is also defined the metric to optimize, in this case we want to _maximize_ the _Accuracy_, and the number of run, which has been set to 20. 

Then the hypedrive run is submitted: what is does is run 20 (in our case) experiments with value randomly chosen by the Sampler. 

**What are the benefits of the parameter sampler you chose?**
The sampler chosen is the RandomParameterSampling where hyperparameter values are randomly selected from the defined search space. RandomParameterSampling is the first choice 

Values chosen are:
* C: uniform(0.05, 1)
* max_iter: choice(20,40,60,80,100,1000)

**What are the benefits of the early stopping policy you chose?**
BanditPolicy has been chosen. The policy terminates any runs that doesn't satisfy the specific slack factor of the best performing run.

Parameters chosen are:
* slack_factor = 0.1
* evaluation_interval=1

It will evaluate every run and will stop a run if the best metric is less then 91% of the best performing.
![alt text](https://github.com/emanuelef1/Optimizing_a_Pipeline_in_Azure/blob/master/hyperdrive.png)

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
AutoML pipeline is fed by the same dataset, then data is cleaned imoprting the clean_data method from train.py.
Then 'classification' is used as task and 'accuracy' as metric. 
AutoML runs more iterations to find the best performing model, which was VotingEnsemble.
![alt text](https://github.com/emanuelef1/Optimizing_a_Pipeline_in_Azure/blob/master/autoML.png)

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? 
In architecture? If there was a difference, why do you think there was one?**

WIth the above configuration AutoML took a bit longer to run, but found the best model wich an accuracy of **0.91557**, while accuracy for Hyperdrive model was **0.910336**
AutoML was much easier to configure with less code to write and yet resulted to be more powerful, with AutoML is also very easy try out different algorithms compared to the single one in hyperdrive.

## Future work
I would like to make more run to improve the hyperdrive model and try other algorithms for hyperdrive.

## Proof of cluster clean up
Cluster has been deleted in the notebook.
